# Configuration file for object detection

[general]
portal=https://yourserver:yourport/zm
user=admin
password=password
allow_self_signed=yes

# sequence of models to run for detection
models=yolo,face

#basic_user=basicusername
#basic_password=basicpassword

# path to store downloaded images
# needs to be RW www-data/apache
image_path=/var/lib/zmeventnotification/images

# this is the global detection pattern used for all monitors.
# choose any set of classes from here https://github.com/pjreddie/darknet/blob/master/data/coco.names
# for everything, make it .*
#detect_pattern=(person|car|motorbike|bus|truck|boat)
detect_pattern=.*

# bestmatch, alarm, snapshot OR a specific frame ID
frame_id=bestmatch

# this is the to resize the image before analysis is done
# leave to 800 unless you are sure - seems to do a good job at this size
resize=800


# set to yes, if you want to remove images after analysis
# setting to yes is recommended to avoid filling up space
# keep to no while debugging/inspecting masks
# Note this does NOT delete debug images later
delete_after_analyze=no

# If yes, will write an image called <filename>-bbox.jpg as well
# which contains the bounding boxes. This has NO relation to 
# write_image_to_zm 
# Typically, if you enable delete_after_analyze you may
# also want to set  write_debug_image to no. 
write_debug_image=yes

# if yes, will write an image with bounding boxes
# this needs to be yes to be able to write a bounding box
# image to ZoneMinder that is visible from its console
write_image_to_zm=yes

# Adds percentage to detections
# hog/face shows 100% always
show_percent=no

# log level can be info,error,debug
log_level=debug

# color to be used to draw the polygons you specified
poly_color=(255,255,255)


## Monitor specific settings
#
# - Format:  [monitor-<mid>]
#
# Parameters:
# polygon areas where object detection will be done.
# You can name them anything except the keywords defined in the optional
# params below. You can put as many polygons as you want per [monitor-<mid>]
# (see examples).
#
# detect_pattern: overrides the detection patterns used for this monitor.
#
# Examples:

[monitor-11]
# my driveway
detect_pattern=(person|car|motorbike|bus|truck|boat)
my_driveway_perimeter=306,356 1003,341 1074,683 154,715
models=yolo
# tiny switches to tiny yolo weights, instead of full Yolo. Much faster, but less accurate

[monitor-7]
# my front door
# here we want anything except potted plant
# exclusion in regular expressions is not
# as straightforward as you may think, so 
# follow this pattern
# detect_pattern = ^(?!object1|object2|objectN)
# the characters in front implement what is 
# called a negative look ahead

detect_pattern=^(?!potted plant|pottedplant)

# local model overrides global
models=yolo,face

[monitor-2]
# my basement
#detect_pattern=(person)
#detect_pattern=.*
detect_pattern=^(?!chair|bed)
param=219,304 1113,278 1066,863 177,852
models=yolo,face

[monitor-5]
# deck
detect_pattern=^(?!chair|table|bench)
models=yolo
yolo_type=tiny
boundary=100,100 2988,10 2988,2220 10,2220


#[monitor-4]
# detect_pattern=(cat|dog)
# kitchen_door=313,221 392,210 418,592 367,659

# No 'detect_pattern', global value would be used.
# [monitor-7]
# entrance_door=313,221 392,210 418,592 367,659

# config files for yolo
[yolo]
config=/var/lib/zmeventnotification/models/yolov3/yolov3.cfg
weights=/var/lib/zmeventnotification/models/yolov3/yolov3.weights
labels=/var/lib/zmeventnotification/models/yolov3/yolov3_classes.txt

tiny_config=/var/lib/zmeventnotification/models/tinyyolo/yolov3-tiny.cfg
tiny_weights=/var/lib/zmeventnotification/models/tinyyolo/yolov3-tiny.weights
tiny_labels=/var/lib/zmeventnotification/models/tinyyolo/yolov3-tiny.txt

# config params for HOG
[hog]
stride=(4,4)
padding=(8,8)
scale=1.05
mean_shift=-1

[face]
known_images_path=/var/lib/zmeventnotification/known_faces

# read https://github.com/ageitgey/face_recognition/wiki/Face-Recognition-Accuracy-Problems
# read https://github.com/ageitgey/face_recognition#automatically-find-all-the-faces-in-an-image
# and play around

# quick overview: 
# num_jitters is how many times to distort images 
# upsample_times is how many times to upsample input images (for small faces, for example)
# model can be hog or cnn. cnn may be more accurate, but I haven't found it to be 

num_jitters=0
model=hog
upsample_times=1
